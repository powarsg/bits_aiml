{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a7445a9f",
      "metadata": {
        "id": "a7445a9f"
      },
      "source": [
        "\n",
        "# DEEP NEURAL NETWORKS – ASSIGNMENT 3  \n",
        "## RNN vs TRANSFORMER FOR TIME SERIES PREDICTION\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba80bdad",
      "metadata": {
        "id": "ba80bdad"
      },
      "source": [
        "\n",
        "**BITS ID:** 2025AA05421  \n",
        "**Name:** Sagar Ganpati Powar  \n",
        "**Email:** 2025aa05421@wilp.bits-pilani.ac.in  \n",
        "**Date:** 07-02-2026\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1a3b6d26",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "1a3b6d26",
        "outputId": "327e9c0a-d213-4e9f-ae0c-6611dd46da25"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-4201011217.py, line 14)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-4201011217.py\"\u001b[0;36m, line \u001b[0;32m14\u001b[0m\n\u001b[0;31m    from tensorflow.keras.layers Amaz(Dense, LSTM, GRU, Input,\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import json\n",
        "import time\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "!pip install tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers Amaz(Dense, LSTM, GRU, Input,\n",
        "    MultiHeadAttention, LayerNormalization,\n",
        "    GlobalAveragePooling1D\n",
        ")\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8083026d",
      "metadata": {
        "id": "8083026d"
      },
      "source": [
        "## PART 1: DATASET LOADING AND EXPLORATION"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Dataset Selection and Loading"
      ],
      "metadata": {
        "id": "lQtntAp1X4qT"
      },
      "id": "lQtntAp1X4qT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "827285e2",
      "metadata": {
        "id": "827285e2"
      },
      "outputs": [],
      "source": [
        "# load dataset\n",
        "url = \"https://raw.githubusercontent.com/plotly/datasets/master/2016-weather-data-seattle.csv\"\n",
        "df = pd.read_csv(url)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)\n",
        "print(\"Original Data shape:\", df.shape)"
      ],
      "metadata": {
        "id": "QdrmZbFjW8ve"
      },
      "id": "QdrmZbFjW8ve",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# select features & subset\n",
        "data = df[['Mean_TemperatureC']].dropna().values\n",
        "data = data[:1500]\n",
        "print(\"Subset records :\", len(data))"
      ],
      "metadata": {
        "id": "dEaN8w8qWweh"
      },
      "id": "dEaN8w8qWweh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = \"Seattle Weather 2016\"\n",
        "dataset_source = url\n",
        "n_samples = len(data)\n",
        "n_features = 1\n",
        "problem_type = \"time_series_forecasting\"\n",
        "\n",
        "# ===============================\n",
        "# Hyperparameters\n",
        "# ===============================\n",
        "sequence_length = 30        # Lookback window (10–50)\n",
        "prediction_horizon = 1      # Steps ahead to predict (1–10)"
      ],
      "metadata": {
        "id": "ABhMx-7RVpep"
      },
      "id": "ABhMx-7RVpep",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Primary metric selection\n",
        "primary_metric = \"RMSE\"\n",
        "metric_justification = \"RMSE penalizes larger temperature prediction errors.\""
      ],
      "metadata": {
        "id": "tXc6OtpAWKrT"
      },
      "id": "tXc6OtpAWKrT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa5ee20e",
      "metadata": {
        "id": "aa5ee20e"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"DATASET INFORMATION\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Dataset: {dataset_name}\")\n",
        "print(f\"Source: {dataset_source}\")\n",
        "print(f\"Total Samples: {n_samples}\")\n",
        "print(f\"Number of Features: {n_features}\")\n",
        "print(f\"Sequence Length: {sequence_length}\")\n",
        "print(f\"Prediction Horizon: {prediction_horizon}\")\n",
        "print(f\"Primary Metric: {primary_metric}\")\n",
        "print(f\"Metric Justification: {metric_justification}\")\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Time Series Exploration"
      ],
      "metadata": {
        "id": "EFAoyzAUX_MK"
      },
      "id": "EFAoyzAUX_MK"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2.1 Plot Time Series Data"
      ],
      "metadata": {
        "id": "X1yFLIGnaVr4"
      },
      "id": "X1yFLIGnaVr4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64133a99",
      "metadata": {
        "id": "64133a99"
      },
      "outputs": [],
      "source": [
        "# 1. Plot Time Series Data\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(data, label=\"Mean Temperature (°C)\")\n",
        "plt.title(\"Seattle Mean Temperature Time Series (First 1500 Samples)\")\n",
        "plt.xlabel(\"Time Steps (Days)\")\n",
        "plt.ylabel(\"Temperature (°C)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2.2 Check for Trend and Seasonality"
      ],
      "metadata": {
        "id": "dk1vZ92ZadAO"
      },
      "id": "dk1vZ92ZadAO"
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Check for Trend and Seasonality\n",
        "series = pd.Series(data.flatten())\n",
        "\n",
        "rolling_mean = series.rolling(window=30).mean()\n",
        "rolling_std = series.rolling(window=30).std()\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(series, label=\"Original Series\")\n",
        "plt.plot(rolling_mean, label=\"30-Day Rolling Mean\", linewidth=2)\n",
        "plt.plot(rolling_std, label=\"30-Day Rolling Std\", linewidth=2)\n",
        "plt.title(\"Trend and Variability Analysis (Rolling Statistics)\")\n",
        "plt.xlabel(\"Time Steps (Days)\")\n",
        "plt.ylabel(\"Temperature (°C)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "D7HDvZnAYytr"
      },
      "id": "D7HDvZnAYytr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2.3 Stationarity Test"
      ],
      "metadata": {
        "id": "UNyguMGBajux"
      },
      "id": "UNyguMGBajux"
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.stattools import adfuller\n",
        "\n",
        "adf_result = adfuller(series)\n",
        "\n",
        "print(\"ADF Statistic:\", adf_result[0])\n",
        "print(\"p-value:\", adf_result[1])\n",
        "print(\"Critical Values:\")\n",
        "for key, value in adf_result[4].items():\n",
        "    print(f\"{key}: {value}\")\n"
      ],
      "metadata": {
        "id": "vHugSbfqapj8"
      },
      "id": "vHugSbfqapj8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "52befe93",
      "metadata": {
        "id": "52befe93"
      },
      "source": [
        "### 1.3 Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5418f9c5",
      "metadata": {
        "id": "5418f9c5"
      },
      "outputs": [],
      "source": [
        "def preprocess_timeseries(data):\n",
        "    scaler = MinMaxScaler()\n",
        "    data_scaled = scaler.fit_transform(data)\n",
        "    return data_scaled, scaler\n",
        "\n",
        "def create_sequences(data, seq_length, pred_horizon):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - seq_length - pred_horizon):\n",
        "        X.append(data[i:i+seq_length])\n",
        "        y.append(data[i+seq_length:i+seq_length+pred_horizon])\n",
        "    return np.array(X), np.array(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a26bf72",
      "metadata": {
        "id": "4a26bf72"
      },
      "outputs": [],
      "source": [
        "# Temporal train/test split (NO SHUFFLING)\n",
        "data_scaled, scaler = preprocess_timeseries(data)\n",
        "X, y = create_sequences(data_scaled, sequence_length, prediction_horizon)\n",
        "\n",
        "split = int(len(X) * 0.9)\n",
        "X_train, X_test = X[:split], X[split:]\n",
        "y_train, y_test = y[:split], y[split:]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Temporal train/test split (NO SHUFFLING)\n",
        "train_test_ratio = \"90/10\"\n",
        "train_samples = len(X_train)\n",
        "test_samples = len(X_test)"
      ],
      "metadata": {
        "id": "iDvPHBR5bNnj"
      },
      "id": "iDvPHBR5bNnj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\nTrain/Test Split: {train_test_ratio}\")\n",
        "print(f\"Training Samples: {train_samples}\")\n",
        "print(f\"Test Samples: {test_samples}\")\n",
        "print(\"⚠️  IMPORTANT: Temporal split used (NO shuffling)\")"
      ],
      "metadata": {
        "id": "3k8utiFsbX24"
      },
      "id": "3k8utiFsbX24",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b02e2357",
      "metadata": {
        "id": "b02e2357"
      },
      "source": [
        "## PART 2 : LSTM Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Architecture Design"
      ],
      "metadata": {
        "id": "g5NNe08Vdfk3"
      },
      "id": "g5NNe08Vdfk3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00a2b07f",
      "metadata": {
        "id": "00a2b07f"
      },
      "outputs": [],
      "source": [
        "# LSTM/GRU Architecture Design\n",
        "def build_rnn_model(model_type, input_shape, hidden_units, n_layers, output_size):\n",
        "    model = Sequential()\n",
        "    for i in range(n_layers):\n",
        "        return_seq = i < n_layers - 1\n",
        "        if model_type == \"LSTM\":\n",
        "            model.add(LSTM(hidden_units, return_sequences=return_seq,\n",
        "                           input_shape=input_shape if i == 0 else None))\n",
        "        else:\n",
        "            model.add(GRU(hidden_units, return_sequences=return_seq,\n",
        "                          input_shape=input_shape if i == 0 else None))\n",
        "    model.add(Dense(output_size))\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create LSTM model\n",
        "lstm_model = build_rnn_model(\"LSTM\", (sequence_length, n_features), 64, 2, prediction_horizon)\n",
        "\n",
        "# Compile LSTM model\n",
        "lstm_model.compile(optimizer=Adam(0.001), loss=\"mse\")\n",
        "\n",
        "lstm_model.summary()"
      ],
      "metadata": {
        "id": "EbgYqJb0cgnt"
      },
      "id": "EbgYqJb0cgnt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Train LSTM Model"
      ],
      "metadata": {
        "id": "6HyFErjedqKA"
      },
      "id": "6HyFErjedqKA"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"RNN MODEL TRAINING\")\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "id": "uds_2vDzeH1p"
      },
      "id": "uds_2vDzeH1p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5a722c2",
      "metadata": {
        "id": "b5a722c2"
      },
      "outputs": [],
      "source": [
        "# Track training time\n",
        "rnn_start_time = time.time()\n",
        "\n",
        "# Train\n",
        "hist_lstm = lstm_model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test, y_test),\n",
        "    verbose=1\n",
        ")\n",
        "rnn_training_time = time.time() - rnn_start_time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_initial_loss = hist_lstm.history['loss'][0]\n",
        "rnn_final_loss = hist_lstm.history['loss'][-1]"
      ],
      "metadata": {
        "id": "K6YhAvi-ea78"
      },
      "id": "K6YhAvi-ea78",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Training completed in {rnn_training_time:.2f} seconds\")\n",
        "print(f\"Initial Loss: {rnn_initial_loss:.4f}\")\n",
        "print(f\"Final Loss: {rnn_final_loss:.4f}\")\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "id": "vgPxCm50em0d"
      },
      "id": "vgPxCm50em0d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 Evaluate RNN Model"
      ],
      "metadata": {
        "id": "0RJoVWqlfUlf"
      },
      "id": "0RJoVWqlfUlf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "024b85ab",
      "metadata": {
        "id": "024b85ab"
      },
      "outputs": [],
      "source": [
        "# Make LSTM predictions on test set\n",
        "y_pred_lstm = lstm_model.predict(X_test)\n",
        "\n",
        "# Inverse transform (since data was normalized)\n",
        "y_test_inv = scaler.inverse_transform(\n",
        "    y_test.reshape(-1, 1)\n",
        ").flatten()\n",
        "\n",
        "y_pred_lstm_inv = scaler.inverse_transform(\n",
        "    y_pred_lstm.reshape(-1, 1)\n",
        ").flatten()\n",
        "\n",
        "def calculate_mape(y_true, y_pred, threshold=1.0):\n",
        "    \"\"\"\n",
        "    MAPE calculated only where |y_true| >= threshold\n",
        "    This avoids instability near zero.\n",
        "    \"\"\"\n",
        "    mask = np.abs(y_true) >= threshold\n",
        "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
        "\n",
        "# Calculate all 4 metrics\n",
        "rnn_mae = mean_absolute_error(y_test_inv, y_pred_lstm_inv)\n",
        "rnn_rmse = np.sqrt(mean_squared_error(y_test_inv, y_pred_lstm_inv))\n",
        "rnn_mape = calculate_mape(y_test_inv, y_pred_lstm_inv)\n",
        "rnn_r2 = r2_score(y_test_inv, y_pred_lstm_inv)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nRNN Model Performance:\")\n",
        "print(f\"MAE:   {rnn_mae:.4f}\")\n",
        "print(f\"RMSE:  {rnn_rmse:.4f}\")\n",
        "print(f\"MAPE:  {rnn_mape:.4f}%\")\n",
        "print(f\"R² Score: {rnn_r2:.4f}\")"
      ],
      "metadata": {
        "id": "QbdEVTW-g_mt"
      },
      "id": "QbdEVTW-g_mt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "289fd35b",
      "metadata": {
        "id": "289fd35b"
      },
      "source": [
        "## PART 3: TRANSFORMER IMPLEMENTATION"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Positional Encoding Implementation"
      ],
      "metadata": {
        "id": "yLVk_Rp7iZtE"
      },
      "id": "yLVk_Rp7iZtE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8225bb28",
      "metadata": {
        "id": "8225bb28"
      },
      "outputs": [],
      "source": [
        "def positional_encoding(seq_len, d_model):\n",
        "    pos = np.arange(seq_len)[:, np.newaxis]\n",
        "    i = np.arange(d_model)[np.newaxis, :]\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
        "    angle_rads = pos * angle_rates\n",
        "\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    return tf.cast(angle_rads, dtype=tf.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Transformer Encoder Architecture"
      ],
      "metadata": {
        "id": "480XnQbPidzY"
      },
      "id": "480XnQbPidzY"
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, Model\n",
        "\n",
        "def build_transformer_model(\n",
        "    seq_length,\n",
        "    n_features,\n",
        "    d_model,\n",
        "    n_heads,\n",
        "    n_layers,\n",
        "    d_ff,\n",
        "    output_size\n",
        "):\n",
        "    inputs = layers.Input(shape=(seq_length, n_features))\n",
        "\n",
        "    # Project input to d_model\n",
        "    x = layers.Dense(d_model)(inputs)\n",
        "\n",
        "    # Add positional encoding\n",
        "    x = x + positional_encoding(seq_length, d_model)\n",
        "\n",
        "    # Stack Transformer encoder layers\n",
        "    for _ in range(n_layers):\n",
        "        # Multi-head self-attention\n",
        "        attn_output = layers.MultiHeadAttention(\n",
        "            num_heads=n_heads,\n",
        "            key_dim=d_model // n_heads\n",
        "        )(x, x)\n",
        "        x = layers.LayerNormalization()(x + attn_output)\n",
        "\n",
        "        # Feed-forward network\n",
        "        ffn_output = layers.Dense(d_ff, activation=\"relu\")(x)\n",
        "        ffn_output = layers.Dense(d_model)(ffn_output)\n",
        "        x = layers.LayerNormalization()(x + ffn_output)\n",
        "\n",
        "    # Output layer\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    outputs = layers.Dense(output_size)(x)\n",
        "\n",
        "    return Model(inputs=inputs, outputs=outputs)\n"
      ],
      "metadata": {
        "id": "EPjuEm7okUrs"
      },
      "id": "EPjuEm7okUrs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 Build Transformer Model"
      ],
      "metadata": {
        "id": "bIxGPoDQivAS"
      },
      "id": "bIxGPoDQivAS"
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_model = build_transformer_model(sequence_length, n_features, d_model=64, n_heads=4, n_layers=2, d_ff=256, output_size=prediction_horizon)\n",
        "\n",
        "transformer_model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss=\"mse\"\n",
        ")\n",
        "\n",
        "transformer_model.summary()"
      ],
      "metadata": {
        "id": "RsgnamPCiuHP"
      },
      "id": "RsgnamPCiuHP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.4 Train Transformer Model"
      ],
      "metadata": {
        "id": "pMBEBed-mdtY"
      },
      "id": "pMBEBed-mdtY"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRANSFORMER MODEL TRAINING\")\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "id": "9QN6ypEWmh3Z"
      },
      "id": "9QN6ypEWmh3Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Track training time\n",
        "transformer_start_time = time.time()\n",
        "\n",
        "hist_transformer = transformer_model.fit(X_train, y_train, epochs=50, batch_size=32)\n",
        "\n",
        "transformer_training_time = time.time() - transformer_start_time"
      ],
      "metadata": {
        "id": "aiEvPc-wmis0"
      },
      "id": "aiEvPc-wmis0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Track initial and final loss\n",
        "transformer_initial_loss = hist_transformer.history['loss'][0]\n",
        "transformer_final_loss = hist_transformer.history['loss'][-1]"
      ],
      "metadata": {
        "id": "yo_8FpYHkai0"
      },
      "id": "yo_8FpYHkai0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Training completed in {transformer_training_time:.2f} seconds\")\n",
        "print(f\"Initial Loss: {transformer_initial_loss:.4f}\")\n",
        "print(f\"Final Loss: {transformer_final_loss:.4f}\")\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "id": "50yHYU5fnEPD"
      },
      "id": "50yHYU5fnEPD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.5 Evaluate Transformer Model"
      ],
      "metadata": {
        "id": "RTDCLix6nKNf"
      },
      "id": "RTDCLix6nKNf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b2a8d9e",
      "metadata": {
        "id": "8b2a8d9e"
      },
      "outputs": [],
      "source": [
        "# Make transaformer predictions on test set\n",
        "y_pred_tr = transformer_model.predict(X_test)\n",
        "\n",
        "# Inverse transform predictions and true values\n",
        "y_test_tr_inv = scaler.inverse_transform(\n",
        "    y_test.reshape(-1, 1)\n",
        ").flatten()\n",
        "\n",
        "y_pred_tr_inv = scaler.inverse_transform(\n",
        "    y_pred_tr.reshape(-1, 1)\n",
        ").flatten()\n",
        "\n",
        "# Calculate all 4 metrics (Transformer)\n",
        "transformer_mae = mean_absolute_error(y_test_tr_inv, y_pred_tr_inv)\n",
        "transformer_rmse = np.sqrt(mean_squared_error(y_test_tr_inv, y_pred_tr_inv))\n",
        "transformer_mape = calculate_mape(y_test_tr_inv, y_pred_tr_inv)\n",
        "transformer_r2 = r2_score(y_test_tr_inv, y_pred_tr_inv)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nTransformer Model Performance:\")\n",
        "print(f\"MAE:   {transformer_mae:.4f}\")\n",
        "print(f\"RMSE:  {transformer_rmse:.4f}\")\n",
        "print(f\"MAPE:  {transformer_mape:.4f}%\")\n",
        "print(f\"R² Score: {transformer_r2:.4f}\")"
      ],
      "metadata": {
        "id": "l-3OiXu-oUvj"
      },
      "id": "l-3OiXu-oUvj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.6 Visualize Transformer Results"
      ],
      "metadata": {
        "id": "kNK77fFjpby6"
      },
      "id": "kNK77fFjpby6"
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(hist_transformer.history['loss'], label='Training Loss')\n",
        "plt.title(\"Transformer Training Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"MSE Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "UXU8wuVYpftt"
      },
      "id": "UXU8wuVYpftt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(y_test_tr_inv, label=\"Actual\")\n",
        "plt.plot(y_pred_tr_inv, label=\"Predicted\")\n",
        "plt.title(\"Transformer: Actual vs Predicted Temperature\")\n",
        "plt.xlabel(\"Time Steps\")\n",
        "plt.ylabel(\"Temperature (°C)\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_4Y62RAbpqys"
      },
      "id": "_4Y62RAbpqys",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "residuals_tr = y_test_tr_inv - y_pred_tr_inv\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(residuals_tr)\n",
        "plt.title(\"Transformer Residuals\")\n",
        "plt.xlabel(\"Time Steps\")\n",
        "plt.ylabel(\"Error (°C)\")\n",
        "plt.axhline(0, color='red', linestyle='--')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-iP08eRMpuOT"
      },
      "id": "-iP08eRMpuOT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PART 4: MODEL COMPARISON AND VISUALIZATION"
      ],
      "metadata": {
        "id": "_ez0MOi8p25j"
      },
      "id": "_ez0MOi8p25j"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Metrics Comparison"
      ],
      "metadata": {
        "id": "OJSU0fR0reHt"
      },
      "id": "OJSU0fR0reHt"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MODEL COMPARISON\")\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "id": "f-NBxMWXriwr"
      },
      "id": "f-NBxMWXriwr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Total trainable parameters\n",
        "rnn_total_params = lstm_model.count_params()\n",
        "transformer_total_params = transformer_model.count_params()\n",
        "\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Metric': ['MAE', 'RMSE', 'MAPE (%)', 'R² Score', 'Training Time (s)', 'Parameters'],\n",
        "    'RNN (LSTM/GRU)': [\n",
        "        rnn_mae,\n",
        "        rnn_rmse,\n",
        "        rnn_mape,\n",
        "        rnn_r2,\n",
        "        rnn_training_time,\n",
        "        rnn_total_params\n",
        "    ],\n",
        "    'Transformer': [\n",
        "        transformer_mae,\n",
        "        transformer_rmse,\n",
        "        transformer_mape,\n",
        "        transformer_r2,\n",
        "        transformer_training_time,\n",
        "        transformer_total_params\n",
        "    ]\n",
        "})"
      ],
      "metadata": {
        "id": "hqR6-xxCro89"
      },
      "id": "hqR6-xxCro89",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(comparison_df.to_string(index=False))\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "id": "nAN2nsXOro5m"
      },
      "id": "nAN2nsXOro5m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 Visual Comparison"
      ],
      "metadata": {
        "id": "DUQosJdjsKzF"
      },
      "id": "DUQosJdjsKzF"
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = ['MAE', 'RMSE', 'R²']\n",
        "lstm_values = [rnn_mae, rnn_rmse, rnn_r2]\n",
        "transformer_values = [ transformer_mae,  transformer_rmse,  transformer_r2]\n",
        "\n",
        "x = np.arange(len(metrics))\n",
        "width = 0.35\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.bar(x - width/2, lstm_values, width, label='LSTM')\n",
        "plt.bar(x + width/2, transformer_values, width, label='Transformer')\n",
        "\n",
        "plt.xticks(x, metrics)\n",
        "plt.ylabel(\"Metric Value\")\n",
        "plt.title(\"Model Performance Comparison\")\n",
        "plt.legend()\n",
        "plt.grid(axis='y')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Bvl97H5Jro0R"
      },
      "id": "Bvl97H5Jro0R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 4))\n",
        "\n",
        "plt.plot(y_test_inv, label='Actual', color='black')\n",
        "plt.plot(y_pred_lstm_inv, label='LSTM Prediction')\n",
        "plt.plot(y_pred_tr_inv, label='Transformer Prediction')\n",
        "\n",
        "plt.title(\"Actual vs Predictions (LSTM vs Transformer)\")\n",
        "plt.xlabel(\"Time Steps\")\n",
        "plt.ylabel(\"Temperature (°C)\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "281rZCDYronr"
      },
      "id": "281rZCDYronr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 4))\n",
        "\n",
        "plt.plot(hist_lstm.history['loss'], label='LSTM Training Loss')\n",
        "plt.plot(hist_transformer.history['loss'], label='Transformer Training Loss')\n",
        "\n",
        "plt.title(\"Training Loss Comparison\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"MSE Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hSV2Rrp8roUc"
      },
      "id": "hSV2Rrp8roUc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "384358a7",
      "metadata": {
        "id": "384358a7"
      },
      "source": [
        "## PART 5: ANALYSIS"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analysis_text = \"\"\"\n",
        "TODO: Write your analysis here (maximum 200 words guideline)\n",
        "\n",
        "Address:\n",
        "1. Which model performed better and by how much?\n",
        "   [Compare specific metrics]\n",
        "\n",
        "2. RNN vs Transformer architecture advantages?\n",
        "   [Discuss sequential processing vs parallel processing]\n",
        "\n",
        "3. Impact of attention mechanism?\n",
        "   [Discuss how attention captures dependencies]\n",
        "\n",
        "4. Long-term dependency handling?\n",
        "   [Compare vanishing gradients vs attention]\n",
        "\n",
        "5. Computational cost comparison?\n",
        "   [Compare training time, parameters]\n",
        "\n",
        "6. Convergence behavior?\n",
        "   [Discuss training stability, loss curves]\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "tdk5ECE7s950"
      },
      "id": "tdk5ECE7s950",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Print analysis with word count\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "print(analysis_text)\n",
        "print(\"=\"*70)\n",
        "print(f\"Analysis word count: {len(analysis_text.split())} words\")\n",
        "if len(analysis_text.split()) > 200:\n",
        "    print(\"⚠️  Warning: Analysis exceeds 200 words (guideline)\")\n",
        "else:\n",
        "    print(\"✓ Analysis within word count guideline\")\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "id": "hx2mWOTns91q"
      },
      "id": "hx2mWOTns91q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PART 6: ASSIGNMENT RESULTS SUMMARY"
      ],
      "metadata": {
        "id": "zhE5n977tK-j"
      },
      "id": "zhE5n977tK-j"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_assignment_results():\n",
        "    \"\"\"\n",
        "    Generate complete assignment results in required format\n",
        "\n",
        "    Returns:\n",
        "        dict: Complete results with all required fields\n",
        "    \"\"\"\n",
        "\n",
        "    framework_used = \"keras\"\n",
        "    rnn_model_type = \"LSTM\"\n",
        "\n",
        "    results = {\n",
        "        # Dataset Information\n",
        "        'dataset_name': dataset_name,\n",
        "        'dataset_source': dataset_source,\n",
        "        'n_samples': n_samples,\n",
        "        'n_features': n_features,\n",
        "        'sequence_length': sequence_length,\n",
        "        'prediction_horizon': prediction_horizon,\n",
        "        'problem_type': problem_type,\n",
        "        'primary_metric': primary_metric,\n",
        "        'metric_justification': metric_justification,\n",
        "        'train_samples': train_samples,\n",
        "        'test_samples': test_samples,\n",
        "        'train_test_ratio': train_test_ratio,\n",
        "\n",
        "        # RNN Model Results\n",
        "        'rnn_model': {\n",
        "            'framework': framework_used,\n",
        "            'model_type': rnn_model_type,\n",
        "            'architecture': {\n",
        "                'n_layers': 2,\n",
        "                'hidden_units': 64,\n",
        "                'total_parameters': rnn_total_params\n",
        "            },\n",
        "            'training_config': {\n",
        "                'learning_rate': 0.001,\n",
        "                'n_epochs': 50,\n",
        "                'batch_size': 32,\n",
        "                'optimizer': 'Adam',\n",
        "                'loss_function': 'MSE'\n",
        "            },\n",
        "            'initial_loss': rnn_initial_loss,\n",
        "            'final_loss': rnn_final_loss,\n",
        "            'training_time_seconds': rnn_training_time,\n",
        "            'mae': rnn_mae,\n",
        "            'rmse': rnn_rmse,\n",
        "            'mape': rnn_mape,\n",
        "            'r2_score': rnn_r2\n",
        "        },\n",
        "\n",
        "        # Transformer Model Results\n",
        "        'transformer_model': {\n",
        "            'framework': framework_used,\n",
        "            'architecture': {\n",
        "                'n_layers': 2,\n",
        "                'n_heads': 4,\n",
        "                'd_model': 64,\n",
        "                'd_ff': 256,\n",
        "                'has_positional_encoding': True,\n",
        "                'has_attention': True,\n",
        "                'total_parameters': transformer_total_params\n",
        "            },\n",
        "            'training_config': {\n",
        "                'learning_rate': 0.001,\n",
        "                'n_epochs': 50,\n",
        "                'batch_size': 32,\n",
        "                'optimizer': 'Adam',\n",
        "                'loss_function': 'MSE'\n",
        "            },\n",
        "            'initial_loss': transformer_initial_loss,\n",
        "            'final_loss': transformer_final_loss,\n",
        "            'training_time_seconds': transformer_training_time,\n",
        "            'mae': transformer_mae,\n",
        "            'rmse': transformer_rmse,\n",
        "            'mape': transformer_mape,\n",
        "            'r2_score': transformer_r2\n",
        "        },\n",
        "\n",
        "        # Analysis\n",
        "        'analysis': analysis_text,\n",
        "        'analysis_word_count': len(analysis_text.split()),\n",
        "\n",
        "        # Training Success Indicators\n",
        "        'rnn_loss_decreased': rnn_final_loss < rnn_initial_loss if rnn_initial_loss and rnn_final_loss else False,\n",
        "        'transformer_loss_decreased': transformer_final_loss < transformer_initial_loss if transformer_initial_loss and transformer_final_loss else False,\n",
        "    }\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "euSTAR6is9wM"
      },
      "id": "euSTAR6is9wM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate and print results\n",
        "try:\n",
        "    assignment_results = get_assignment_results()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"ASSIGNMENT RESULTS SUMMARY\")\n",
        "    print(\"=\"*70)\n",
        "    print(json.dumps(assignment_results, indent=2))\n",
        "    print(\"=\"*70)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n⚠️  ERROR generating results: {str(e)}\")\n",
        "    print(\"Please ensure all variables are properly defined\")"
      ],
      "metadata": {
        "id": "Z6j-RhSks9o_"
      },
      "id": "Z6j-RhSks9o_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display system information\n",
        "import platform\n",
        "import sys\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "2qBhcaNis9eZ"
      },
      "id": "2qBhcaNis9eZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Environment Details\n",
        "env_info = {\n",
        "    \"python_version\": sys.version,\n",
        "    \"tensorflow_version\": tf.__version__,\n",
        "    \"platform\": platform.platform()\n",
        "}"
      ],
      "metadata": {
        "id": "XYO7CCx5s9Ip"
      },
      "id": "XYO7CCx5s9Ip",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*70)\n",
        "print(\"ENVIRONMENT INFORMATION\")\n",
        "print(json.dumps(env_info, indent=2))\n",
        "print(\"=\"*70)\n",
        "print(\"\\n⚠️  REQUIRED: Add screenshot of your Google Colab/BITS Virtual Lab\")\n",
        "print(\"showing your account details in the cell below this one.\")\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "id": "_jnHmrSfvSF4"
      },
      "id": "_jnHmrSfvSF4",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}