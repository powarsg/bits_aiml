{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "080a2062-6efb-4905-8c89-4d6b63fa3196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Reading training data...\n",
      " preprocess_data ...\n",
      "  Before : ['datetime', 'season', 'holiday', 'workingday', 'weather', 'temp', 'atemp', 'humidity', 'windspeed', 'casual', 'registered', 'count']\n",
      "  After : ['season', 'holiday', 'workingday', 'weather', 'temp', 'humidity', 'windspeed', 'hour', 'day', 'month', 'year', 'weekday', 'is_weekend', 'is_commute_hour', 'is_night']\n",
      "  Fitting & transforming X ...\n",
      "  X transformed shape: (10450, 61)\n",
      "3. Split train-test data...\n",
      "4. train model : linear_regression\n",
      "5. train model : ridge\n",
      "6. train model : lasso\n",
      "7. train model : random_forest\n",
      "8. train model : gradient_boosting\n",
      "\n",
      "9. Evaluate models ...\n",
      "                      RMSLE       RMSE        MAE        R2\n",
      "Linear Regression  0.610896  97.363086  61.856613  0.711028\n",
      "Ridge Regression   0.610842  97.386207  61.851350  0.710891\n",
      "Lasso Regression   0.611516  98.094007  62.027979  0.706673\n",
      "Random Forest      0.387113  41.607428  25.587240  0.947227\n",
      "Gradient Boosting  0.384784  50.884093  31.125403  0.921072\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Custom RMSLE Function\n",
    "# ---------------------------------------------------------\n",
    "def rmsle(y_true, y_pred):\n",
    "    y_pred = np.maximum(0, y_pred)  # avoid negative values\n",
    "    y_true = np.maximum(0, y_true)\n",
    "    return np.sqrt(np.mean((np.log1p(y_pred) - np.log1p(y_true))**2))\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Model functions\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def train_linear_regression(X_train, y_train):\n",
    "    print('4. train model : linear_regression')\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_ridge(X_train, y_train, alpha=1.0):\n",
    "    print('5. train model : ridge')\n",
    "    model = Ridge(alpha=alpha)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_lasso(X_train, y_train, alpha=0.001):\n",
    "    print('6. train model : lasso')\n",
    "    model = Lasso(alpha=alpha, max_iter=20000)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_random_forest(X_train, y_train, n_estimators=300, max_depth=15, random_state=42):\n",
    "    print('7. train model : random_forest')\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        random_state=random_state,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_gradient_boosting(X_train, y_train, learning_rate=0.05, n_estimators=500, max_depth=4, random_state=42):\n",
    "    print('8. train model : gradient_boosting')\n",
    "    model = GradientBoostingRegressor(\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Evaluate model (correct handling of log-transformed target)\n",
    "# ---------------------------------------------------------\n",
    "def evaluate_model(model, X_test, y_test_log):\n",
    "    # Convert y_test back to original count scale\n",
    "    y_true = np.expm1(y_test_log)\n",
    "\n",
    "    # Predict log(count)\n",
    "    y_pred_log = model.predict(X_test)\n",
    "\n",
    "    # Convert prediction back\n",
    "    y_pred = np.expm1(y_pred_log)\n",
    "\n",
    "    # Safety for RMSLE\n",
    "    y_pred = np.maximum(0, y_pred)\n",
    "\n",
    "    return {\n",
    "        \"RMSLE\": rmsle(y_true, y_pred),\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        \"R2\": r2_score(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Feature Engineering\n",
    "# ---------------------------------------------------------\n",
    "def add_derived_features(df):\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    \n",
    "    df['hour'] = df['datetime'].dt.hour\n",
    "    df['day'] = df['datetime'].dt.day\n",
    "    df['month'] = df['datetime'].dt.month\n",
    "    df['year'] = df['datetime'].dt.year\n",
    "    df['weekday'] = df['datetime'].dt.weekday\n",
    "\n",
    "    df['is_weekend'] = df['weekday'].isin([5, 6]).astype(int)\n",
    "    df['is_commute_hour'] = df['hour'].isin([7, 8, 9, 17, 18, 19]).astype(int)\n",
    "    df['is_night'] = df['hour'].isin([0, 1, 2, 3, 4, 5]).astype(int)\n",
    "\n",
    "    df = df.drop(columns=['datetime'])\n",
    "    return df\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Preprocessing\n",
    "# ---------------------------------------------------------\n",
    "def preprocess_data(df):\n",
    "    print(' preprocess_data ...')\n",
    "\n",
    "    # LOG TRANSFORM TARGET\n",
    "    y_log = np.log1p(df['count'])\n",
    "\n",
    "    print(f'  Before : {list(df.columns)}')\n",
    "   \n",
    "    df = add_derived_features(df)\n",
    "\n",
    "    # Remove dependent fields\n",
    "    df = df.drop(columns=['count', 'casual', 'registered'])\n",
    "\n",
    "    # Remove redundant field\n",
    "    df = df.drop(columns=['atemp'])\n",
    "\n",
    "    print(f'  After : {list(df.columns)}')\n",
    "\n",
    "    X = df.copy()\n",
    "\n",
    "    # Numeric features\n",
    "    numeric_features = ['temp', 'humidity', 'windspeed']\n",
    "    numeric_transformer = StandardScaler()\n",
    "\n",
    "    # Categorical (One-Hot)\n",
    "    categorical_features = ['season', 'weather', 'hour', 'month', 'weekday']\n",
    "    categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "    # Build full transformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    print(\"  Fitting & transforming X ...\")\n",
    "    X_transformed = preprocessor.fit_transform(X)\n",
    "\n",
    "    # convert sparse â†’ dense\n",
    "    if hasattr(X_transformed, \"toarray\"):\n",
    "        X_transformed = X_transformed.toarray()\n",
    "\n",
    "    print(\"  X transformed shape:\", X_transformed.shape)\n",
    "\n",
    "    return X_transformed, y_log, preprocessor\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Main\n",
    "# ---------------------------------------------------------\n",
    "print(\"1. Reading training data...\")\n",
    "df = pd.read_csv(\"bike_train.csv\")\n",
    "\n",
    "# Preprocess\n",
    "X_processed, y_log, preprocessor = preprocess_data(df)\n",
    "\n",
    "# Train/Test Split\n",
    "print('3. Split train-test data...')\n",
    "X_train, X_test, y_train_log, y_test_log = train_test_split(\n",
    "    X_processed, y_log, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train Models\n",
    "lin_model = train_linear_regression(X_train, y_train_log)\n",
    "ridge_model = train_ridge(X_train, y_train_log)\n",
    "lasso_model = train_lasso(X_train, y_train_log)\n",
    "rf_model = train_random_forest(X_train, y_train_log, n_estimators=500, max_depth=25)\n",
    "gb_model = train_gradient_boosting(X_train, y_train_log, learning_rate=0.05, n_estimators=600, max_depth=4)\n",
    "\n",
    "# Evaluate\n",
    "print(\"\\n9. Evaluate models ...\")\n",
    "results = {\n",
    "    \"Linear Regression\": evaluate_model(lin_model, X_test, y_test_log),\n",
    "    \"Ridge Regression\": evaluate_model(ridge_model, X_test, y_test_log),\n",
    "    \"Lasso Regression\": evaluate_model(lasso_model, X_test, y_test_log),\n",
    "    \"Random Forest\": evaluate_model(rf_model, X_test, y_test_log),\n",
    "    \"Gradient Boosting\": evaluate_model(gb_model, X_test, y_test_log),\n",
    "}\n",
    "\n",
    "print(pd.DataFrame(results).T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bce5e0c-734f-494f-b07f-33b21fcc068b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
